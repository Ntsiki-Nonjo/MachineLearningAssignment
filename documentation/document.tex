\documentclass[12pt]{article}

\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, margin=2.54cm]{geometry}

\hypersetup{
	linktocpage,
	colorlinks=true,
	linkcolor=gray
}
\setlength{\arrayrulewidth}{0.5mm}
\setlength{\tabcolsep}{15pt}
\renewcommand{\arraystretch}{1.2}

\begin{document}
	
	\begin{titlepage}
		
		\centering
		
		{\bfseries\LARGE
			Machine Learning\\
			Assignment
		}
		\vfill
		\includegraphics[width=7cm]{img/logo.png}
		\vfill
		\begin{center}
			{\bfseries\LARGE Members}\\
			{\bfseries\large
				815108 N. Nonjoli\\
				805494 D. Khumalo\\
				1126619 O.N. Mekgwe\\
			}
		\end{center}
		\vfill
		\thispagestyle{empty}
	\end{titlepage}

	\tableofcontents
	\thispagestyle{empty}
	\newpage
	
	\section{Introduction}
	\setcounter{page}{1}
	\subsection{What is Supervised Learning?}
	
	\newpage
	
	\section{Dataset}
	\subsection{Description}
	The aim of this dataset is to predict whether a person earns \$50,000 per annum. This
	dataset has 14 variables, is multivariate and the area of focus is social.
	\begin{center}
		\begin{tabular}{|p{3cm}|p{12cm}|}
			\hline
			\multicolumn{2}{|c|}{\bfseries\Large Adult Data Set} \\
			\hline
			Attribute&Description\\
			\hline
			age&continuous\\
			workclass& Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked\\
			fnlwg&continuous\\
			education&Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool\\
			education-num&continuous\\
			marital-status&Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse\\
			occupation&Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces\\
			relationship&Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried\\
			race&White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black\\
			sex&Female, Male\\
			capital-gain&continuous\\
			capital-loss&continuous\\
			hours-per-week&continuous\\
			native-country&United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad and Tobago, Peru, Hong, Holand-Netherland\\
			\hline
			\multicolumn{2}{|c|}{\bfseries\large 48842 Datapoints} \\
			\hline
		\end{tabular}
	\end{center}
	
	\subsection{Targets}
	\subsection{Sample}
	\subsection{What are we predicting?}
	\newpage
	
	\section{Algorithms}
	\subsection{Decision Tree}
	\subsubsection{Description}
	\subsubsection{How data was handled}
	\subsubsection{Reason}
	\subsubsection{Performance}
	\newpage
	\subsection{Gaussian Na\"{\i}ve Bayes}
	\subsubsection{Description}
	Gaussian Na\"{\i}ve Bayes is one of Na\"{\i}ve Bayes modelling algorithms used for classification with an assumption of normal distribution of the data features.
	\subsubsection{How data was handled}
	Considering that we had some categorical data and given the fact that Gaussian Na\"{\i}ve Bayes works with continuous input data, a label encoder method had to be imported from the sklearn python library in order to convert the categorical data into continuous data. In other words strings matching the category where encoded into numbers.This was needed to allow the GaussianNB() method from the sklearn.naive bayes library to fit the training data into the model. Also the data had to include non-nulls thus a dropna() method was used to remove any missing values in the dataset. Column headers also had to be added into the dataset which mirrored the attributes given to us from the dataset repository (https://archive.ics.uci.edu/ml/datasets/Adult). Afterwards training and testing data were split with a test size ratio of 0.2 produced at random, this allowed us to fit the non-biased training data into the Gaussian Naive Bayes model.
	\subsubsection{Reasons} 
	Since we are given a classification problem, Gaussian Na\"{\i}ve Bayes is a simple and efficient model to implement given that it is one-dimensional. Also from a coding perspective, the algorithm is quick to implement as there is support from the sklearn python library. The Na\"{\i}ve Bayes algorithm works well with large datasets giving an almost accurate and fast way of prediction
	\subsubsection{Performance}
	As stated above the algorithm models large data quickly and efficiently. With our dataset the model produced an accuracy level of 0.804514742014742.  
	\newpage
	\subsection{Linear Regression}
	\subsubsection{Description}
	\subsubsection{How data was handled}
	\subsubsection{Reason}
	\subsubsection{Performance}
	\newpage
	\section{Results}
	\subsection{Findings}
	\subsubsection{Best Algorithm}
	\subsubsection{Worst Algorithm}
	\subsection{Recommendations}
	
\end{document}
