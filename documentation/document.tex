\documentclass[12pt]{article}

\usepackage{xcolor}
\usepackage{sectsty}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, margin=2.54cm]{geometry}

\hypersetup{
	linktocpage,
	colorlinks=true,
	linkcolor=gray,
	filecolor=olive,
	urlcolor=darkgray,
	citecolor=darkgray
}

\sectionfont{\color{brown}}

\setlength{\arrayrulewidth}{0.5mm}
\setlength{\tabcolsep}{15pt}
\renewcommand{\arraystretch}{1.2}

\begin{document}
	
	\begin{titlepage}
		
		\centering
		
		{\bfseries\LARGE
			Machine Learning\\
			Assignment
		}
		\vfill
		\includegraphics[width=7cm]{img/logo.png}
		\vfill
		\begin{center}
			{\bfseries\LARGE Members}\\
			{\bfseries\large
				815108 N. Nonjoli\\
				805494 D. Khumalo\\
				1126619 O.N. Mekgwe\\
			}
		\end{center}
		\vfill
		\thispagestyle{empty}
	\end{titlepage}

	\tableofcontents
	\thispagestyle{empty}
	\newpage
	
	\section{Introduction}
	\setcounter{page}{1}
	\subsection{What is Supervised Learning?}
	
	\newpage
	
	\section{Dataset}
	\subsection{Description}
	The aim of this dataset is to predict whether a person earns \$50,000 per annum. This
	dataset has 14 variables, is multivariate and the area of focus is social.
	\begin{center}
		\begin{tabular}{|p{2cm}|p{12cm}|}
			\hline
			\multicolumn{2}{|c|}{\bfseries\Large Adult Data Set} \\
			\hline
			Attribute&Values\\
			\hline
			age&Age of person\\
			workclass&Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked\\
			fnlwg&continuous\\
			education&Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool\\
			education-num&continuous\\
			marital-status&Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse\\
			occupation&Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces\\
			relationship&Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried\\
			race&White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black\\
			sex&Female, Male\\
			capital-gain&continuous\\
			capital-loss&continuous\\
			hours-per-week&continuous\\
			native-country&United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad and Tobago, Peru, Hong, Holand-Netherland\\
			\hline
			\multicolumn{2}{|c|}{\bfseries\large 48842 Datapoints} \\
			\hline
		\end{tabular}
	\end{center}

	\setlength{\arrayrulewidth}{0.0mm}
	\setlength{\tabcolsep}{15pt}
	\renewcommand{\arraystretch}{1.2}
	
	\subsection{Terminology}
	\begin{tabular}{|p{3cm}|p{1cm}|p{10cm}|}
		{\bfseries Age}&:&Age of person\\
		{\bfseries Work Class}&:&Class of work\\
		{\bfseries Final Weight}&:&Final weight of how much of the population it represents\\
		{\bfseries Education}&:&Education level\\
		{\bfseries Education Number}&:&Numeric education level\\
		{\bfseries Occupation}&:&Occupation of the person\\
		{\bfseries Relationship}&:&Type of relationship\\
		{\bfseries Sex}&:&Gender of the person\\
		{\bfseries Capital Gain}&:&Rise in value of an investment or real estate that gives it a higher worth than the purchase price\\
		{\bfseries Capital Loss}&:&Loss incured when an investment or real estate decreases in value\\
		{\bfseries Hours}&:&Average number of working hours per week\\
		{\bfseries Native Country}&:&Country of origin\\
	\end{tabular}
	
	\subsection{Targets}
	\subsection{Sample}
	\subsection{What are we predicting?}
	\newpage
	
	\section{Algorithms}
	
	% decision tree
	\subsection{Decision Tree}
	\subsubsection{Description}
	
	Decision Trees are used to classify data, the classification can either be categorical or continuous. They are a type of Supervised Machine Learning. The tree can be described by decision nodes and leaves. The leaves describe the final outcomes, and the decision nodes are where the data is split\cite{decision-tree-explanation}.
	
	\subsubsection{How data was handled}
	
	The following was done to prepare the data:
	\begin{itemize}
		\item Headers were added and saved to a new file \href{run:../data/adult.csv}{adult.csv}
		\item Rows that had missing variables were removed from the data set.
		\item Redundant attributes/columns were removed, i.e: education-num
	\end{itemize}

	\subsubsection{Reason}
	\subsubsection{Performance}
	\newpage
	
	% gaussian naive bayes
	\subsection{Gaussian Na\"{\i}ve Bayes}
	\subsubsection{Description}
	Gaussian Na\"{\i}ve Bayes is one of Na\"{\i}ve Bayes modelling algorithms used for classification with an assumption of normal distribution of the data features.
	\subsubsection{How data was handled}
	Considering that we had some categorical data and given the fact that Gaussian Na\"{\i}ve Bayes works with continuous input data, a label encoder method had to be imported from the sklearn python library in order to convert the categorical data into continuous data. In other words strings matching the category where encoded into numbers.This was needed to allow the GaussianNB() method from the sklearn.naive bayes library to fit the training data into the model. Also the data had to include non-nulls thus a dropna() method was used to remove any missing values in the dataset. Column headers also had to be added into the dataset which mirrored the attributes given to us from the dataset repository (\url{https://archive.ics.uci.edu/ml/datasets/Adult}). Afterwards training and testing data were split with a test size ratio of 0.2 produced at random, this allowed us to fit the non-biased training data into the Gaussian Naive Bayes model.
	\subsubsection{Reasons} 
	Since we are given a classification problem, Gaussian Na\"{\i}ve Bayes is a simple and efficient model to implement given that it is one-dimensional. Also from a coding perspective, the algorithm is quick to implement as there is support from the sklearn python library. The Na\"{\i}ve Bayes algorithm works well with large datasets giving an almost accurate and fast way of prediction
	\subsubsection{Performance}
	As stated above the algorithm models large data quickly and efficiently. With our dataset the model produced an accuracy level of 0.804514742014742.  
	\newpage
	
	% linear regression
	\subsection{Logistic Regression}
	\subsubsection{Description}
	\subsubsection{How data was handled}
	\subsubsection{Reason}
	\subsubsection{Performance}
	\newpage
	
	
	
	\section{Results}
	\subsection{Findings}
	\subsubsection{Best Algorithm}
	\subsubsection{Worst Algorithm}
	\subsection{Recommendations}
	\newpage
	
	\begin{thebibliography}{9}
		\bibitem{weight-and-income}
		Does thinking you look fat affect how much money you earn?
		\\\texttt{\url{https://www.timeslive.co.za/sunday-times/lifestyle/health-and-sex/2018-07-23-does-thinking-you-look-fat-affect-how-much-money-you-earn/}}
		
		\bibitem{decision-tree-explanation}
		Decision Trees for Classification: A Machine Learning Algorithm
		\\\texttt{\url{https://www.xoriant.com/blog/product-engineering/decision-trees-machine-learning-algorithm.html}}
	\end{thebibliography}
	
\end{document}
